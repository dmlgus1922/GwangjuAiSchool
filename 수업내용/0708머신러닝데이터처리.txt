머신러닝
 -지도학습: 문제(입력)와 답(결과)을 함께 학습
    회귀(Linear, Polynomial)
     -연속형 값인 y의 특징을 찾아 데이터x를 사용하여 y값을 예측하는 기법
    *의사결정트리, 랜덤 포레스트 
    분류(kNN, Trees, Logistic Regression, Naive-Bayes, SVM)
     -이산형 값인 y의 특징을 찾아 데이터x를 사용하여 y값을 예측하는 기법

 -비지도 학습: 조력자의 도움 없이 컴퓨터 스스로 학습. 컴퓨터가 훈련 데이터를 이용하여 데이터들 간의 규칙성을 찾아낸다.
    클러스터링(SVD, PCA, K-means)
     -y값이 주어지지 않고, 데이터의 특징이 유사한 값들의 모임을 군집으로 표현하는 기법
 
 -강화 학습: 보상과 체벌을 하듯 컴퓨터가 세상에 존재하는 규칙을 시뮬레이션을 돌려 게임처럼 규칙을 학습.

 -생성: 세상에 존재하는 다양한 규칙을 학습한 모델이 세상에 존재하지 않는 새로운 무엇인가를 창조한다.
    *컴퓨터로 사람의 얼굴 생성, 컴퓨터가 챗봇 형태로 인간과 대화 등

머신러닝의 4가지 단계
 - 훈련 데이터 수집
    데이터가 없으면 학습 자체가 불가. 
    목적에 맞는 훈련 데이터를 수집해야한다.

 - 입력 데이터 분석 및 준비
 - 학습
    기본적인 모델(상관관계의 식)의 틀을 만들어야 한다.
 - 예측 및 테스트
    

* 특징을 선택할 때:
    데이터 간 유사성이 50%에 가까운 확률을 가지는 특징들은 제외
    개체들을 구분하는 데 효과가 없는 중복된 특징들도 제외
    (ex. 발이 넷, 수염이 있고 몸집이 작은 강아지와 고양이는 학습하는 데에 큰 의미를 갖지 못할 것.)
    확실하게 개체들을 독립적으로 구분할 수 있는 특징들을 선택
    다수의 특징들을 사용하면 더욱 효과적

*특징이란 우리가 학습 모델에게 공급하는 입력이다. 가장 간단한 경우에는 입력 자체가 특징이 된다.
*라벨
 - y=f(x)에서 y변수에 해당
 - 예를 들어 농작물의 향후 가격, 사진에 표시되는 동물, 동영상의 의미 등 무엇이든 레이블이 될 수 있다.
*샘플 또는 예제
 - 기계학습에 주어지는 특정한 예. y=f(x)에서 x에 해당한다.
 - 레이블이 있는 샘플, 없는 샘플도 있다.

*학습은 모델을 만들거나 배우는 것을 의미.
*예측은 학습된 모델을 레이블이 없는 샘플에 적용하는 것. 학습된 모델을 사용해 유용한 예측을 하는 것이다.

특징(입력), 라벨(결과)

결정트리 학습 모델(Decision Tree Learning Model)
 어떤 항목에 대한 목표값을 연결해주는 예측 모델로써 결정트리를 사용하는 방식
 의사결정 규칙과 그 결과들을 트리 구조로 생성
 *트리: 계층적


회귀: 독립변수 x와 종속변수 y의 관계를 함수식으로 설명.
    추세선을 표현히는 수학적 모델을 만드는 기법.
    입력에서 출력의 함수를 학습하는 것.
분류: 데이터를 어떤 기준으로 나눔
    입력을 두 개 이상의 라벨로 분할하는 것
    해당 모델을 학습시킬 때 우리는 라벨을 제공해야 한다.
    이진분류(2개의 값 중 1개를 분류), 다중분류

군집: 기존에 모여 있던 데이터에 대해 따로 분류 기준을 주지 않고 모델이 스스로 분류 기준을 찾아 집단을 모으는 기법
    제일 베이직한 비지도 학습

강화학습: 컴퓨터가 어떤 행동을 취할 때마다 외부에서 처벌이나 보상이 주어진다.
    알파고 최종 버전도 강화 학습 사용.(ex. 흑이 이길 때 보상, 백이 이길 때 처벌)

머신러닝
- 프로그래밍 시간을 줄일 수 있다.
    규칙을 만들지 않아도 수많은 예제만 주는 것
- 맞춤형 제품을 쉽게 개발할 수 있다.
- 프로그래머로 시도할 알고리즘이 떠오르지 않는 문제들을 해결할 수도 있다.
    알고리즘을 짜기 위해 수많은 지식과 경험이 필요한 전통적 방법에 비해 머신러닝은 수많은 예제를 주는 걸로 가능.

---------------------------------------------------------
*지도학습은 크게 회귀와 분류로 나눌 수 있다.
*회귀는 주어진 입출력 쌍을 학습하고 새 입력값이 들어왔을 때 합리적인 출력을 예측하는 것
*분류: 입력을 두 개 이상의 유형으로 분할.
*비지도학습은 숨겨진 구조를 발견하는 것이다.
*강화학습은 반응형 문제 해결이다.
---------------------------------------------------------


데이터

데이터는 어떠한 값의 모음
값이 모여있는 방식에 따라 정형, 반졍형, 비정형 데이터로 나눈다.
데이터 과학에서는 정형 데이터를 주로 사용.
반정형, 비정형 데이터를 다룬다 해도 정형화하여 분석한다.
정형 데이터는 열과 행이 있는 데이터 테이블.

텍스트 마이닝
비정형 데이터의 분석. 현실에는 정형 데이터보다 비정형 데이터가 많다.
즉 이를 잘 다루는 것이 중요하며 비정형 데이터를 분석하는 것을 텍스트마이닝이라 한다.

텍스트 마이닝의 절차
 1. 텍스트 마이닝 대상이 되는 코퍼스(말뭉치) 준비
 2. 코퍼스에 대해 숫자나 문장 부호 등을 제거(영문인 경우 모두 소문자로 변환)
 3. 불용어 제거
 4. 어간 추출
 5. DTM(Document-Term Matrix, 문서 단어 행렬) 생성


선형대수
-
데이터를 다루는 데이터 과학에서는 값이 정량화되어 기록되기 때문에 이러한 정량화된 값을 잘 다루는 것이 상당히 중요하다.
그에 따라 수학적 접근과 이해의 중요성이 부각되고 있다.
수학, 확률, 통계는 데이터 과학의 여러 컴퓨팅 기법과 머신러닝, 딥러닝의 바탕이 되며, 데이터를 다루는 학제적인 영역에서 일종의 '공용어'역할.
데이터 과학은 여러 분야를 다루므로 그 분야들과의 협업이 필수적인데, 이때 수학, 확률, 통계가 이들 간에 의사소통이 가능하게 해준다.
-
선형대수를 간단히 말하자면 주어진 데이터를 2차원과 같은 어떤 공간으로 표현한 것.

벡터: 방향과 크기를 갖는 직선.
    2차원의 직선이 될 수도 있고 더 많은 차원에서의 직선으로도 표현
    벡터의 원소
     세로로 표현하는 경우 종벡터(열벡터)
     가로로 표현하는 경우 횡벡터(행벡터)
     두 형태 가운데 종벡터를 더 많이 사용하는 편이다.
    몇 가지 숫자를 세로로 나란히 나타낸 것

행렬:
    숫자를 가로 세로로 표처럼 늘어놓은 것
    수나 기호, 수식 등을 네모꼴로 배열한 것


데이터 전처리
머신러닝 모델에 훈련 데이터를 입력하기 전에 데이터를 가공하는 것

데이터 품질 문제
 1. 데이터 분포의 지나친 차이
    데이터가 연속형 값인데 최댓값과 최솟값의 차이가 피쳐보다 더 많이 나는 경우
    학습에 영향을 주기 때문에 데이터의 스케일을 맞춰줘야 함
    데이터의 최댓값과 최솟값을 0에서 1 사이 값으로 바꾸거나 표준 정규분포 형태로 나타내는 등의 방식이 있다.
 
 2. 기수형 데이터와 서수형 데이터
    컴퓨터가 이해하도록 데이터를 바꿔야 한다.
 
 3. 결측치
    데이터를 빼고 모델을 돌릴 수 없으므로 처리를 해야한다.
    중간값으로 채우기, 아예 데이터를 없애기 등.
    
    - 판다스를 임포트 해 데이터프레임을 만들고 isnull메소드와 sum메소드를 사용하면 시리즈마다 결측치의 개수를 확인할 수 있다.
    df.isnull().sum()과 같이 쓴다
    또한 df.isnull().sum().len(df) 시리즈마다 결측치 비율을 나타내준다.

    - 결측치 처리:
        드롭
         데이터를 삭제하거나 데이터를 채운다.(평균, 최빈값, 중간값 등으로 채움)
         드롭을 했다고 원본이 바뀌는 것은 아니다. 새로 만들어주는 것. 따라서 다른 변수에 재할당하거나 매개변수 inplace=True를 사용해야함
         df.dropna()를 하면 nan을 가진 인스턴스를 날려버린다.
         + dropna()에는 기본 매개변수 how='any'가 있는데 all로 바꿔주면 인스턴스 객체에 있는 값이 전부 nan일 때 날려준다.
         'any'일 때는 하나라도 nan일 때 인스턴스를 날려주는 것.
         + 추가로 axis가 기본값으로 0으로 지정되어 있는데 이를 1로 설정하면 피쳐 정보를 날려줄 수도 있다.
         ex) df.dropna(how='all', axis=1) => 결측치만 존재하는 피쳐를 지워준다.
         + dropna의 thresh 매개변수에 값을 지정하면 해당 값의 수 이상만큼 데이터를 가진 인스턴스(축을 변경하면 피쳐)를 제외하고 제거해버린다.
        
        채우기
        fillna()메소드를 사용하지만 데이터프레임 전체적으로 사용하면 입력하는 값에 따라 데이터에 혼동이 올 수 있다.
         ex) 이산형 데이터에 이상한 값이 들어감(성별에 남성, 여성이 아닌 0)
        시리즈 객체마다의 결측치를 채워주면 데이터에 혼동이 오는 것을 막는다.
         ex) df.피쳐.fillna(df.피쳐.mean(), inplace = True) 평균값으로 결측치 채우고 데이터프레임에 저장하기
        groupby로 피쳐로 그룹화하고 다른 피쳐를 가진 시리즈에 transform 메소드를 사용해 그룹된 피쳐를 기준으로 값을 채운다.
         ex) df.groupby('기준피쳐')['값을 채울 피쳐'].transform('mean') => '값을 채울 피쳐'의 각 데이터에 '기준피쳐'로 나뉜 값들의 평균값을 넣어준다.
            * '값을 채울 피쳐'에는 값이 있지만 '기준피쳐'에 값이 없는 인스턴스는 값을 잃어버릴 수도 있다.         
            * 일반적으로 쓰이는 방법
                -기준이 있는 대상의 평균값으로 결측치 채우기
                 df.'값을채울피쳐'.fillna(df.groupby('기준피쳐')['값을 채울 피쳐'].transform('mean'), inplace=True)
 4. 이상치
    극단적으로 크거나 작은 값이다.
    단순히 데이터 분포의 차이와는 다르다.
    일반적으로 오기입으로 발생, 특이 현상으로 나타난다.
    머신러닝에선 제거해주는 것이 좋겠지만 딥러닝에선 이상치 자체도 데이터로서 의미를 가지므로 제거하지 않는 경우가 있다.
    오기입으로 나타난 것인지 특이 현상으로 나타난 것인지 판단하는 것도 중요한 능력이다.

범주형 데이터 처리 - 원핫 인코딩
    pd.get_dummies 메소드로 데이터 타입이 'object'인 데이터를 값이 있을 때 1, 없을 때 0으로 바꿔준다.
    특정 피쳐가 있다 없다를 판단하므로 범주의 수만큼 피쳐가 늘어난다.
    ex) 색상이란 피쳐에 '빨강','파랑'이라는 범주 데이터가 있을 때 해당 데이터를 가지면 1, 아니면 0으로 나타내주는 '색상_빨강', '색상_파랑'과 같은 모습의 피쳐가 생겨난다.
    